{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3f9775",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import urllib.request\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "import json\n",
    "\n",
    "objects = []\n",
    "articles = [\n",
    "    ['cbt', \"https://en.wikipedia.org/wiki/Cognitive_behavioral_therapy\"],\n",
    "    ['vr', \"https://en.wikipedia.org/wiki/Virtual_reality\"],\n",
    "    ['ai', \"https://en.wikipedia.org/wiki/Artificial_intelligence\"]\n",
    "]\n",
    "for [topic, url] in articles:\n",
    "    html = urlopen(url)\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    paras = []\n",
    "    for para in soup.find(id=\"mw-content-text\").find_all('p'):\n",
    "        para = para.get_text()\n",
    "        para = para.replace('\\n', ' ')\n",
    "        para = re.sub(r\"\\[[0-9]+\\]\", \"\", para)\n",
    "        if len(para) < 10:\n",
    "            continue\n",
    "        # para = re.sub(r\"\\[[0-9]*\\]\", \"\", para)\n",
    "        if len(paras) == 0:\n",
    "            paras.append(para)\n",
    "        elif len(para) < 100:\n",
    "            paras[len(paras) - 1] += para\n",
    "        else:\n",
    "            paras.append(para)\n",
    "    for i, para in enumerate(paras):\n",
    "        doc = dict(\n",
    "            text=para,\n",
    "            title=f\"{topic}{i}\"\n",
    "        )\n",
    "        objects.append(doc)\n",
    "\n",
    "with open(\"mock_entries.json\", \"w\") as f:\n",
    "    f.write(json.dumps(objects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a4cc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_GPU = False\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "import json\n",
    "\n",
    "from haystack.document_stores.faiss import FAISSDocumentStore\n",
    "\n",
    "document_store = FAISSDocumentStore.load('./index.faiss', './index.config')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a015084",
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.nodes import DensePassageRetriever\n",
    "dpr_retriever = DensePassageRetriever(\n",
    "    document_store=document_store,\n",
    "    use_gpu=False\n",
    "    # query_embedding_model=\"facebook/dpr-question_encoder-single-nq-base\",\n",
    "    # passage_embedding_model=\"facebook/dpr-ctx_encoder-single-nq-base\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ef46c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from haystack.nodes import RAGenerator\n",
    "rag_generator = RAGenerator(\n",
    "    model_name_or_path=\"facebook/rag-sequence-nq\",\n",
    "    retriever=dpr_retriever,\n",
    "    top_k=3,\n",
    "    min_length=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53742695",
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.pipelines import GenerativeQAPipeline\n",
    "\n",
    "from haystack.nodes import FARMReader\n",
    "from haystack.pipelines import ExtractiveQAPipeline\n",
    "reader = FARMReader(model_name_or_path=\"deepset/roberta-base-squad2\", use_gpu=False)\n",
    "pipe = ExtractiveQAPipeline(reader, dpr_retriever)\n",
    "result = pipe.run(query='What is CBT?', params={\"Retriever\": {\"top_k\": 5}})\n",
    "a = 1\n",
    "\n",
    "# # Change `minimum` to `medium` or `all` to raise the level of detail\n",
    "# print_answers(result, details=\"all\")\n",
    "print(result)\n",
    "return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "633b44ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from txtai.embeddings import Embeddings\n",
    "\n",
    "# Create embeddings model, backed by sentence-transformers & transformers\n",
    "embeddings = Embeddings({\"path\": \"sentence-transformers/nli-mpnet-base-v2\", \"content\":True})\n",
    "\n",
    "data = {\n",
    "  \"uid1\": {\"text\": \"US tops 5 million confirmed virus cases\", \"obj_id\": \"obj_id1\"},\n",
    "  \"uid1\": {\"text\": \"Canada's last fully intact ice shelf has suddenly collapsed\", \"obj_id\": \"obj_id2\"},\n",
    "  \"uid1\": {\"text\": \"forming a Manhattan-sized iceberg\", \"obj_id\": \"obj_id3\"},\n",
    "  \"uid1\": {\"text\": \"Beijing mobilises invasion craft along coast as Taiwan tensions escalate\", \"obj_id\": \"obj_id4\"},\n",
    "  \"uid1\": {\"text\": \"The National Park Service warns against sacrificing slower friends \", \"obj_id\": \"obj_id5\"},\n",
    "  \"uid1\": {\"text\": \"in a bear attack\", \"obj_id\": \"obj_id6\"},\n",
    "  \"uid1\": {\"text\": \"Maine man wins $1M from $25 lottery ticket\", \"obj_id\": \"obj_id7\"},\n",
    "  \"uid1\": {\"text\": \"Make huge profits without work, earn up to $100,000 a day\", \"obj_id\": \"obj_id8\"}\n",
    "}\n",
    "\n",
    "embeddings.index([\n",
    "    (uid, obj, None) \n",
    "    for uid, obj in data.items()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ccda43b",
   "metadata": {},
   "outputs": [
    {
     "ename": "IntegrityError",
     "evalue": "UNIQUE constraint failed: sections.indexid",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIntegrityError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [17], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m transform \u001b[38;5;241m=\u001b[39m Transform(embeddings, \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tempfile\u001b[38;5;241m.\u001b[39mNamedTemporaryFile(mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m, suffix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m buffer:\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;66;03m# Load documents into database and transform to vectors\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m         ids, dimensions, vecs \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m ids:\n\u001b[1;32m     13\u001b[0m             \u001b[38;5;66;03m# Normalize embeddings\u001b[39;00m\n\u001b[1;32m     14\u001b[0m             embeddings\u001b[38;5;241m.\u001b[39mnormalize(vecs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/txtai/embeddings/transform.py:58\u001b[0m, in \u001b[0;36mTransform.__call__\u001b[0;34m(self, documents, buffer)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;124;03mProcesses an iterable collection of documents, handles any iterable including generators.\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;124;03m    (document ids, dimensions, embeddings)\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# Transform documents to vectors and load into database\u001b[39;00m\n\u001b[0;32m---> 58\u001b[0m ids, dimensions, batches, stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# Check that embeddings are available and load as a memmap\u001b[39;00m\n\u001b[1;32m     61\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/txtai/vectors/base.py:79\u001b[0m, in \u001b[0;36mVectors.index\u001b[0;34m(self, documents, batchsize)\u001b[0m\n\u001b[1;32m     77\u001b[0m stream \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m     78\u001b[0m batch \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 79\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m document \u001b[38;5;129;01min\u001b[39;00m documents:\n\u001b[1;32m     80\u001b[0m     batch\u001b[38;5;241m.\u001b[39mappend(document)\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(batch) \u001b[38;5;241m==\u001b[39m batchsize:\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;66;03m# Convert batch to embeddings\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/txtai/embeddings/transform.py:117\u001b[0m, in \u001b[0;36mTransform.stream\u001b[0;34m(self, documents)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m# Final batch\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/txtai/embeddings/transform.py:142\u001b[0m, in \u001b[0;36mTransform.load\u001b[0;34m(self, batch, offset)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;66;03m# Load batch into database except if this is a reindex\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdatabase \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction \u001b[38;5;241m!=\u001b[39m Action\u001b[38;5;241m.\u001b[39mREINDEX:\n\u001b[0;32m--> 142\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatabase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;66;03m# Load batch into graph\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/txtai/database/sqlite.py:151\u001b[0m, in \u001b[0;36mSQLite.insert\u001b[0;34m(self, documents, index)\u001b[0m\n\u001b[1;32m    148\u001b[0m     document \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;66;03m# Save text section\u001b[39;00m\n\u001b[0;32m--> 151\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsertsection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocument\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mentry\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    152\u001b[0m index \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/txtai/database/sqlite.py:433\u001b[0m, in \u001b[0;36mSQLite.insertsection\u001b[0;34m(self, index, uid, text, tags, entry)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;124;03mInserts a section.\u001b[39;00m\n\u001b[1;32m    423\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;124;03m    entry: generated entry date\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;66;03m# Save text section\u001b[39;00m\n\u001b[0;32m--> 433\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSQLite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mINSERT_SECTION\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mentry\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mIntegrityError\u001b[0m: UNIQUE constraint failed: sections.indexid"
     ]
    }
   ],
   "source": [
    "from txtai.embeddings.transform import Transform\n",
    "import tempfile\n",
    "from uuid import uuid4\n",
    "documents = [\n",
    "    (str(uuid4()), doc['text'], None) \n",
    "    for uid, doc in data.items()\n",
    "]\n",
    "transform = Transform(embeddings, 3)\n",
    "with tempfile.NamedTemporaryFile(mode=\"wb\", suffix=\".npy\") as buffer:\n",
    "        # Load documents into database and transform to vectors\n",
    "        ids, dimensions, vecs = transform(documents, buffer)\n",
    "        if ids:\n",
    "            # Normalize embeddings\n",
    "            embeddings.normalize(vecs)\n",
    "\n",
    "            # Save index dimensions\n",
    "            embeddings.config[\"dimensions\"] = dimensions\n",
    "vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b12f4be6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.search(\"select id, text, obj_id, score from txtai where similar('ice shelf')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d1c925c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings.save('./tmp_stuff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7a4ced8",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Embeddings' object has no attribute 'embeddings'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43membeddings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Embeddings' object has no attribute 'embeddings'"
     ]
    }
   ],
   "source": [
    "embeddings.embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d23a5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import numpy as np\n",
    "import pyarrow.parquet as pq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "065a9b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame([\n",
    "    {'text': 'para1', 'embedding': np.array([1.,2.,3.])},\n",
    "    {'text': 'para2', 'embedding': np.array([3.,4.,5.])},\n",
    "    {'text': 'para3', 'embedding': np.array([6.,7.,8.])},\n",
    "])\n",
    "\n",
    "df2 = pd.DataFrame([\n",
    "    {'text': 'para4', 'embedding': np.array([9.,10.,11.])},\n",
    "    {'text': 'para5', 'embedding': np.array([12.,13.,14.])},\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08cbf6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = \"s3://legion4-gnothi-ml-mlbucket1277e4f8-4ug4t2pcc0e2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a003fe7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "\n",
    "table1 = pa.Table.from_pandas(df1)\n",
    "table2 = pa.Table.from_pandas(df2)\n",
    "\n",
    "pq.write_table(table1, f\"{bucket}/tmp/user1/paras/1.parque\")\n",
    "pq.write_table(table2, f\"{bucket}/tmp/user1/paras/2.parque\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "892f24fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>obj_id</th>\n",
       "      <th>obj_type</th>\n",
       "      <th>content</th>\n",
       "      <th>created_at</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>564803ba-6194-41a5-8805-2ea5d38f1041</td>\n",
       "      <td>564803ba-6194-41a5-8805-2ea5d38f1041</td>\n",
       "      <td>entry</td>\n",
       "      <td>Fields are activity &amp; quality trackers. Mood, ...</td>\n",
       "      <td>2022-12-26T04:45:17.021Z</td>\n",
       "      <td>[0.035571013, -0.03464019, -0.06016851, 0.0528...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90fc5e66-f4d3-418f-89c0-63508d428161</td>\n",
       "      <td>90fc5e66-f4d3-418f-89c0-63508d428161</td>\n",
       "      <td>entry</td>\n",
       "      <td>Fields are activity &amp; quality trackers. Mood, ...</td>\n",
       "      <td>2022-12-26T04:40:15.171Z</td>\n",
       "      <td>[0.035571013, -0.03464019, -0.06016851, 0.0528...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e196d3c7-04c5-4388-b30d-1ac547e129e6</td>\n",
       "      <td>e196d3c7-04c5-4388-b30d-1ac547e129e6</td>\n",
       "      <td>entry</td>\n",
       "      <td>Fields are activity &amp; quality trackers. Mood, ...</td>\n",
       "      <td>2022-12-26T04:37:20.682Z</td>\n",
       "      <td>[0.035571013, -0.03464019, -0.06016851, 0.0528...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id                                obj_id  \\\n",
       "0  564803ba-6194-41a5-8805-2ea5d38f1041  564803ba-6194-41a5-8805-2ea5d38f1041   \n",
       "1  90fc5e66-f4d3-418f-89c0-63508d428161  90fc5e66-f4d3-418f-89c0-63508d428161   \n",
       "2  e196d3c7-04c5-4388-b30d-1ac547e129e6  e196d3c7-04c5-4388-b30d-1ac547e129e6   \n",
       "\n",
       "  obj_type                                            content  \\\n",
       "0    entry  Fields are activity & quality trackers. Mood, ...   \n",
       "1    entry  Fields are activity & quality trackers. Mood, ...   \n",
       "2    entry  Fields are activity & quality trackers. Mood, ...   \n",
       "\n",
       "                 created_at                                          embedding  \n",
       "0  2022-12-26T04:45:17.021Z  [0.035571013, -0.03464019, -0.06016851, 0.0528...  \n",
       "1  2022-12-26T04:40:15.171Z  [0.035571013, -0.03464019, -0.06016851, 0.0528...  \n",
       "2  2022-12-26T04:37:20.682Z  [0.035571013, -0.03464019, -0.06016851, 0.0528...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pq\n",
    "  .read_table(f\"s3://legion4-gnothi-ml-mlbucket1277e4f8-4ug4t2pcc0e2/vectors/0519cbef-7c24-4b98-9363-c25d00567bb7/entries\")\n",
    "  .to_pandas()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37f69b0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>item1</td>\n",
       "      <td>[1.0, 2.0, 3.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>item2</td>\n",
       "      <td>[1.0, 2.0, 3.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>item3</td>\n",
       "      <td>[1.0, 2.0, 3.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a      b              vec\n",
       "0  1  item1  [1.0, 2.0, 3.0]\n",
       "1  2  item2  [1.0, 2.0, 3.0]\n",
       "2  3  item3  [1.0, 2.0, 3.0]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_read.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1513d0f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No axis named 1 for object type Series",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/generic.py:554\u001b[0m, in \u001b[0;36mNDFrame._get_axis_number\u001b[0;34m(cls, axis)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_AXIS_TO_AXIS_NUMBER\u001b[49m\u001b[43m[\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 1",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/generic.py:11847\u001b[0m, in \u001b[0;36mNDFrame._add_numeric_operations.<locals>.mean\u001b[0;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11829\u001b[0m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[1;32m  11830\u001b[0m     _num_doc,\n\u001b[1;32m  11831\u001b[0m     desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturn the mean of the values over the requested axis.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11845\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m  11846\u001b[0m ):\n\u001b[0;32m> 11847\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mNDFrame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/generic.py:11401\u001b[0m, in \u001b[0;36mNDFrame.mean\u001b[0;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11393\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\n\u001b[1;32m  11394\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  11395\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m lib\u001b[38;5;241m.\u001b[39mNoDefault \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mno_default,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11399\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m  11400\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[0;32m> 11401\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stat_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  11402\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnanops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnanmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m  11403\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/generic.py:11353\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[0;34m(self, name, func, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11343\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m  11344\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing the level keyword in DataFrame and Series aggregations is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m  11345\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated and will be removed in a future version. Use groupby \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11348\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m  11349\u001b[0m     )\n\u001b[1;32m  11350\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_by_level(\n\u001b[1;32m  11351\u001b[0m         name, axis\u001b[38;5;241m=\u001b[39maxis, level\u001b[38;5;241m=\u001b[39mlevel, skipna\u001b[38;5;241m=\u001b[39mskipna, numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only\n\u001b[1;32m  11352\u001b[0m     )\n\u001b[0;32m> 11353\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  11354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\n\u001b[1;32m  11355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/series.py:4793\u001b[0m, in \u001b[0;36mSeries._reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m   4790\u001b[0m delegate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m   4792\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4793\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_axis_number\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4795\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(delegate, ExtensionArray):\n\u001b[1;32m   4796\u001b[0m     \u001b[38;5;66;03m# dispatch to ExtensionArray interface\u001b[39;00m\n\u001b[1;32m   4797\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m delegate\u001b[38;5;241m.\u001b[39m_reduce(name, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/generic.py:556\u001b[0m, in \u001b[0;36mNDFrame._get_axis_number\u001b[0;34m(cls, axis)\u001b[0m\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_AXIS_TO_AXIS_NUMBER[axis]\n\u001b[1;32m    555\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m--> 556\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo axis named \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for object type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: No axis named 1 for object type Series"
     ]
    }
   ],
   "source": [
    "df[df.a < 3].vec.mean(axis=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
