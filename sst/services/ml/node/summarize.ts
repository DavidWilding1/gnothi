import {lambdaSend} from "../../aws/handlers"
import {Function} from "sst/node/function";
import * as S from '@gnothi/schemas'
import {TextsParamsMatch} from "./errors";
import {Config} from 'sst/node/config'
import {v4 as uuid} from 'uuid'
import {sendInsight} from "./utils";
import {completion} from "./openai";
import {getSummary} from '@gnothi/schemas/entries'

// set this if using a model that can handle long text, like LongT5. When using long models, we don't necessarily
// need to split text into chunks, and in the accuracy is better when we don't.
const COMBINE_PARAS = true

interface Params {
  summarize?: {
    min_length: number
    max_length: number
  }
  // https://github.com/MaartenGr/KeyBERT
  keywords?: {
    keyphrase_ngram_range?: [number, number]
    stop_words?: "english"

    use_mmr?: boolean, // true
    diversity?: number, // 0.7

    use_maxsum?: boolean, // True,
    nr_candidates?: number // 20,
    top_n?: number
  }
  emotion?: boolean
}

export const keywordsDefaults: Params['keywords'] = {
  keyphrase_ngram_range: [1, 1],
  stop_words: "english",
  use_mmr: true,
  diversity: .10
}

interface FnIn {
  texts: string[]
  params: Params[]
  usePrompt: boolean
}
type LambdaIn = {
  usePrompt: boolean
  data: Array<{
    text: string,
    params: Params
  }>
}
export type SummarizeOut = {
  summary: string
  keywords: string[]
  emotion: string
}
type LambdaOut = Array<SummarizeOut>
type FnOut = LambdaOut

const combinedPrompt = `
Provide a title, summary, keywords, and emotion for the following entry. They keywords should follow this format: theme1(keyword1,keyword2;a summary of theme1)|theme2(keyword1,keyword2;a summary of theme2). The emotion should be one of (anger, disgust, fear, joy, neutral, sadness, surprise). Here's a sample output format:

Title: The singularity is near
Summary: Artificial intelligence is improving at a rapid clip. Large language models like GPT4 and Llama are increasingly capable, passing various human benchmarks like the Bar Exam, and even the Turing test. Stable Diffusion is able to create art which is indistinguishable from human creativity. Neural Link is coming soon, a harbinger of full-dive VR. Video games now have AI NPCs, which can talk and act creatively in their environments.
Emotion: surprise
Themes: Large Language Models(llm,gpt,openai;LLMs like GPT pass the Turing Test);AI Art(art,stable diffusion,midjourney;AI art is near-perfect);Virtual Reality(vr,games,bci;VR is incorporating AI via AI NPCs, generative art, and Brain Computer Interfaces)

Now here's the article to generate output for:

<journal>`

// this was generated by GPT, clean it up when I get a chance
function parseGptOutput(output: string) {
  const titleMatch = output.match(/Title: (.*)\n/);
  const summaryMatch = output.match(/Summary: (.*)\n/);
  const emotionMatch = output.match(/Emotion: (.*)\n/);
  const themesMatch = output.match(/Themes: (.*)/);

  const title = titleMatch ? titleMatch[1] : '';
  const summary = summaryMatch ? summaryMatch[1] : '';
  const emotion = emotionMatch ? emotionMatch[1] : '';
  const themesString = themesMatch ? themesMatch[1] : '';

  const themes = themesString.split(';').map((themeStr) => {
    const [titleKeywords, summary] = themeStr.split('|');
    const [title, keywordsStr] = titleKeywords.split('(');
    const keywords = keywordsStr.replace(')', '').split(',');
    return { title: title.trim(), keywords, summary: summary.trim() };
  });

  return { title, summary, emotion, themes };
}

/**
 * I've had a hell of a time with huggingface summarizers. They lean too heavily on
 * the training data, and everything sounds like news. I've played with hyperparameters
 * till I'm blue in the face, and I'm giving up for now and using OpenAI TLDR instead.
 */
async function summarizeOpenai(data: LambdaIn['data'][0]): Promise<SummarizeOut> {
  const {params, text} = data

  // replace all \n with ' ' before master-prompting
  const textOneLine = text.replace(/[\n\r]+/g, ' ')

  // Even with any of keywords,emotion,summary disabled; crafting our combinedPrompt over time makes this easier to
  // get right, and we can just remove the results before returning
  const response = await completion({
    max_tokens: 512,
    prompt: combinedPrompt.replace("<journal>", textOneLine),
  })

  const output = parseGptOutput(response)
  debugger
  return output
}


async function summarize_({usePrompt, data}: LambdaIn): Promise<LambdaOut> {
  if (usePrompt) {
    return Promise.all(data.map(summarizeOpenai))
  } else {
    // Get fnName while inside function because will only be present for FnBackground (not FnMain)
    const fnName = Config.FN_SUMMARIZE_NAME
    const res = await lambdaSend<LambdaOut>(data, fnName, "RequestResponse")
    return res.Payload
  }

}

export async function summarize({texts, params, usePrompt}: FnIn): Promise<FnOut> {
  if (params.length === 1) {
    return summarize_({
      usePrompt,
      data: [{
        text: texts.join('\n'),
        params: params[0]
      }]
    })
  } else if (texts.length === params.length && params.length > 0) {
    const data = texts.map((text, i) => ({
      text,
      params: params[i]
    }))
    return summarize_({usePrompt, data})
  }
}

/**
 * Helper function for summarize on insights page
 */
interface SummarizeInsights {
  entries: S.Entries.Entry[]
  context: S.Api.FnContext
  usePrompt: boolean
}
export async function summarizeInsights({context, entries}: SummarizeInsights): Promise<FnOut> {
  let summaries: FnOut
  if (entries.length === 0) {
    summaries = []
  } else if (entries.length === 1) {
    // just use summary
    summaries = [{
      summary: entries[0].ai_text,
      keywords: entries[0].ai_keywords,
      emotion: entries[0].ai_sentiment
    }]
  } else {
    summaries = await summarize({
      // summarize summaries, NOT full originals (to reduce token max)
      texts: [entries.map(getSummary).join('\n')],
      params: [{
        summarize: {min_length: 10, max_length: 60},
        keywords: keywordsDefaults,
        emotion: true
      }],
      usePrompt: false
    })
  }
  await sendInsight(
    S.Routes.routes.insights_summarize_response,
    summaries[0],
    context
  )
  return summaries
}


/**
 * Helper function just for summarizing entries on submit
 */

interface SummarizeEntryIn {
  text: string
  paras: string[]
  usePrompt: boolean
}
export interface SummarizeEntryOut {
  title: string
  paras: string[]
  body: {
    text: string
    emotion: string
    keywords: string[]
  }
}

const paramsExtra = {keywords: keywordsDefaults, emotion: true}
const params = {
  title: {summarize: {min_length: 3, max_length: 15}},
  para: {summarize: {min_length: 15, max_length: 50}},
  text: {summarize: {min_length: 40, max_length: 120}, ...paramsExtra},
  extra: paramsExtra
}

export async function summarizeEntry({text, paras, usePrompt}: SummarizeEntryIn): Promise<SummarizeEntryOut> {
  // This shouldn't happen, but I haven't tested to ensure
  if (paras.length === 0) {
    throw "paras.length === 0, investigate"
  }

  if (COMBINE_PARAS || paras.length === 1) {
    // The entry was a single paragraph. Don't bother with paragraph magic, just summarize wam-bam
    const joined = paras.join('\n')
    const [title, body] = await summarize({
      texts: [joined, joined],
      params: [params.title, params.text],
      usePrompt
    })
    return {
      title: title.summary,
      paras: [body.summary],
      body: {
        text: body.summary,
        emotion: body.emotion,
        keywords: body.keywords
      }
    }
  }

  // Multiple paragraphs. Ideal scenario, we can summarize each paragraph then concatenate, which helps us
  // with the max-tokens for summarization thing
  const sumParas = (await summarize({
    texts: paras,
    params: [params.para],
    usePrompt
  })).map(p => p.summary)
  const joined = sumParas.join(' ')
  const [title, body] = await summarize({
    texts: [joined, joined],
    params: [params.title, params.text],
    usePrompt
  })
  return {
    title: title.summary,
    paras: sumParas,
    body: {
      text: body.summary,
      emotion: body.emotion,
      keywords: body.keywords
    }
  }
}
