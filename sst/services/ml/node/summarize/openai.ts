import {lambdaSend} from "../../../aws/handlers"
import {Function} from "sst/node/function";
import * as S from '@gnothi/schemas'
import {TextsParamsMatch} from "../errors";
import {Config} from 'sst/node/config'
import {v4 as uuid} from 'uuid'
import {sendInsight} from "../utils";
import {completion} from "../openai";
import {getSummary} from '@gnothi/schemas/entries'
import {insights_themes_response} from' @gnothi/schemas/themes'
import {keywordsDefaults} from "./summarizer";
const r = S.Routes.routes
import {SummarizeEntryIn, SummarizeEntryOut} from './summarizer'

type ThemesOut = insights_themes_response['themes']

interface FnIn {
  texts: string[]
}
export type FnOut = {
  title: string
  summary: string
  keywords: string[]
  emotion: string
}
type ParsedCompletion = {
  title: string
  summary: string
  emotion: string
  themes: {
    word: string
    keywords: string[]
    summary: string
  }[]
}

const combinedPrompt = `
Provide a title, summary, keywords, and emotion for the following entry. They keywords should follow this format: theme1[keyword1,keyword2]a summary of theme1|theme2[keyword1,keyword2]a summary of theme2. The emotion should be one of [anger, disgust, fear, joy, neutral, sadness, surprise]. Here's a sample output format:

Title:The singularity is near
Summary:Artificial intelligence is improving at a rapid clip. Large language models like GPT4 and Llama are increasingly capable, passing various human benchmarks like the Bar Exam, and even the Turing test. Stable Diffusion is able to create art which is indistinguishable from human creativity. Neural Link is coming soon, a harbinger of full-dive VR. Video games now have AI NPCs, which can talk and act creatively in their environments.
Emotion:surprise
Themes:Large Language Models[llm,gpt,openai]LLMs like GPT pass the Turing Test|AI Art[art,stable-diffusion,midjourney]AI art is near-perfect|Virtual Reality[vr,games,bci]VR is incorporating AI via AI NPCs, generative art, and Brain Computer Interfaces

Now here's the article to generate output for:

<journal>`

// this was generated by GPT, clean it up when I get a chance
function parseCompletion(output): ParsedCompletion {
  const [titleLine, summaryLine, emotionLine, themesLine] = output.split('\n');

  const title = titleLine.replace(/Title:\s*/, '');
  const summary = summaryLine.replace(/Summary:\s*/, '');
  const emotion = emotionLine.replace(/Emotion:\s*/, '');

  const themeRegExp = /(\w+)\[([^\]]+)\](.*?)(?=\||$)/g;
  let match;
  const themes = [];

  while ((match = themeRegExp.exec(themesLine)) !== null) {
    const [, themeTitle, keywordsStr, themeSummary] = match;
    const keywords = keywordsStr.split(',');
    themes.push({
      word: themeTitle,
      keywords,
      summary: themeSummary.trim(),
    });
  }

  return {title, summary, emotion, themes};
}

function squashTexts(lines: string[]): string {
  // join all lines together, and regex replace all \n with space
  return lines.join('\n').replace(/[\n\r]+/g, ' ')
}

/**
 * I've had a hell of a time with huggingface summarizers. They lean too heavily on
 * the training data, and everything sounds like news. I've played with hyperparameters
 * till I'm blue in the face, and I'm giving up for now and using OpenAI TLDR instead.
 */
export async function summarize({texts}: FnIn): Promise<ParsedCompletion> {
  // replace all \n with ' ' before master-prompting
  const squashed = squashTexts(texts)

  // Even with any of keywords,emotion,summary disabled; crafting our combinedPrompt over time makes this easier to
  // get right, and we can just remove the results before returning
  const response = await completion({
    max_tokens: 512,
    prompt: combinedPrompt.replace("<journal>", squashed),
  })

  return parseCompletion(response)
}

/**
 * Helper function for summarize on insights page
 */
interface SummarizeInsights {
  entries: S.Entries.Entry[]
  context: S.Api.FnContext,
}
export async function summarizeInsights({context, entries}: SummarizeInsights) {
  async function sendInsights(parsed: ParsedCompletion): Promise<FnOut> {
    const themes: ThemesOut = parsed.themes
    const keywords = themes.map(t => t.keywords).flat()
    await Promise.all([
      sendInsight(
        r.insights_summarize_response,
        {...parsed, keywords},
        context
      ),
      sendInsight(
        r.insights_themes_response,
        parsed,
        context
      )
    ])
  }

  if (entries.length === 0) {
    return sendInsights({
      title: "",
      summary: "Nothing to summarize",
      emotion: "neutral",
      themes: []
    })
  }
  const parsed = await summarize({
    // summarize summaries, NOT full originals (to reduce token max)
    texts: [squashTexts(entries.map(getSummary))],
  })
  return sendInsights(parsed)
}


export async function summarizeEntry({text, paras}: SummarizeEntryIn): Promise<SummarizeEntryOut> {
  // This shouldn't happen, but I haven't tested to ensure
  if (paras.length === 0) {
    throw "paras.length === 0, investigate"
  }

  const parsed = await summarize({
    // summarize summaries, NOT full originals (to reduce token max)
    texts: [squashTexts(paras)],
  })

  return {
    title: parsed.title,
    paras: [parsed.summary],
    body: {
      text: parsed.summary,
      emotion: parsed.emotion,
      keywords: parsed.themes.map(t => t.keywords).flat(),
    }
  }
}
